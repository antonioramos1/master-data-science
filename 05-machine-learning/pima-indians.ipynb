{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Data: Pima Indian Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References:\n",
    "\n",
    "- Sebastian Perez - Machine Learning class\n",
    "- http://lightgbm.readthedocs.io/en/latest/Parameters.html  \n",
    "- http://scikit-learn.org/stable/index.html  \n",
    "- https://xgboost.readthedocs.io/en/latest/parameter.html  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem statement \n",
    "Using the UCI PIMA Indian Diabetes dataset to predict a person has diabetes or not using the medical attributes provided. (Target is column 8)\n",
    "\n",
    "### Assumptions\n",
    "\n",
    "This is enough data to split and reliably predict if the patient has diabetes, the dataset has only 786 data points\n",
    "Just these attributes are enough to diagnose the ailment\n",
    "Similar Problems \n",
    "This is very much like some common 2 class classification problems like classifying mail into spam and ham based on the contents of the email. Obviously the attributes there would be strings and not numbers like this dataset, therefore the way in which we process at least some of the features will be different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore', category=DeprecationWarning) #hides deprecation issue as a consecuence of an update to np\n",
    "\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./pima-indians-diabetes.data\",header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0    1   2   3    4     5      6   7  8\n",
      "0  6  148  72  35    0  33.6  0.627  50  1\n",
      "1  1   85  66  29    0  26.6  0.351  31  0\n",
      "2  8  183  64   0    0  23.3  0.672  32  1\n",
      "3  1   89  66  23   94  28.1  0.167  21  0\n",
      "4  0  137  40  35  168  43.1  2.288  33  1\n",
      "Shape:  (768, 9)\n",
      "Nulls:  0\n"
     ]
    }
   ],
   "source": [
    "print(df.head())\n",
    "print(\"Shape: \", df.shape)\n",
    "print(\"Nulls: \", df.isnull().any().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df[np.arange(8)].values\n",
    "y_train = df[8].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.model_selection import train_test_split\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC 0.651\n",
      "KNeighborsClassifier 0.724\n",
      "DecisionTreeClassifier 0.7227\n",
      "RandomForestClassifier 0.7305\n",
      "LogisticRegression 0.7683\n",
      "LGBMClassifier 0.7487\n",
      "XGBClassifier 0.7657\n"
     ]
    }
   ],
   "source": [
    "classifiers = [SVC(), KNeighborsClassifier(),DecisionTreeClassifier(),RandomForestClassifier(),\n",
    "               LogisticRegression(), LGBMClassifier(), XGBClassifier()]\n",
    "\n",
    "for clf in classifiers:\n",
    "    print(clf.__class__.__name__, cross_val_score(clf, X_train, y_train,\n",
    "                                                  cv=5, scoring=\"accuracy\",verbose=False).mean().round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_svc = SVC(random_state = 0)\n",
    "param_grid_svc = {\n",
    "    \"C\":[2],\n",
    "#     \"gamma\":[1,0.1,0.001,0.0001],\n",
    "    \"kernel\":[\"linear\"] #rbf\n",
    "}\n",
    "\n",
    "clf_knn = KNeighborsClassifier()\n",
    "param_grid_knn = {\n",
    "   \"n_neighbors\":np.arange(1,15),\n",
    "}\n",
    "\n",
    "clf_tree = DecisionTreeClassifier(random_state=0)\n",
    "param_grid_tree = {\n",
    "   \"min_samples_leaf\":np.arange(5,50),\n",
    "    \"max_depth\":np.arange(1,10)\n",
    "}\n",
    "\n",
    "clf_forest = RandomForestClassifier(random_state=0)\n",
    "param_grid_forest = {\n",
    "    \"n_estimators\": [50, 100, 200, 300],\n",
    "    \"max_depth\": np.arange(10,100,10),\n",
    "    \"min_samples_leaf\": np.arange(3,8),\n",
    "#     \"min_samples_split\": [8, 10, 12],\n",
    "}\n",
    "\n",
    "clf_logit = LogisticRegression(random_state=0)\n",
    "param_grid_logit = {\n",
    "    \"C\":[1,10,100,1000],\n",
    "}\n",
    "\n",
    "clf_lgbm = LGBMClassifier()\n",
    "param_grid_lgbm = {\n",
    "    \"learning_rate\": [0.0065],#np.arange(0.005,0.5,0.05),\n",
    "    \"n_estimators\": [300],\n",
    "    \"num_leaves\": [15], #np.arange(10,40,5),\n",
    "    \"min_data_in_leaf\": [30],\n",
    "    \"boosting_type\" : [\"gbdt\"],\n",
    "    \"objective\" : [\"binary\"],\n",
    "    \"seed\":[0],\n",
    "}\n",
    "\n",
    "clf_xgb = XGBClassifier()\n",
    "param_grid_xgb = {\n",
    "#    \"n_estimators\":np.arange(50,300,50),\n",
    "#    \"learning_rate\":np.arange(0.005,0.5,0.05),\n",
    "#    \"max_depth\": np.arange(4,10),\n",
    "    \"nthread\":[-1],\n",
    "    \"seed\":[0]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfs = [clf_svc, clf_knn, clf_tree, clf_forest, clf_logit, clf_lgbm, clf_xgb]\n",
    "param_grids = [param_grid_svc, param_grid_knn, param_grid_tree, param_grid_forest, \n",
    "               param_grid_logit, param_grid_lgbm, param_grid_xgb]\n",
    "\n",
    "def grid_cv(clf,param_grid):\n",
    "\n",
    "    grid_search = GridSearchCV(clf, param_grid=param_grid,scoring = \"accuracy\", \n",
    "                           cv=5, n_jobs=-1) #verbose=2\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    print(clf.__class__.__name__, grid_search.best_params_)\n",
    "    print(\"Accuracy {}\".format(grid_search.best_score_.round(3)))\n",
    "    return(clf.__class__.__name__, grid_search.best_score_.round(3),grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC {'C': 2, 'kernel': 'linear'}\n",
      "Accuracy 0.767\n",
      "KNeighborsClassifier {'n_neighbors': 14}\n",
      "Accuracy 0.758\n",
      "DecisionTreeClassifier {'max_depth': 7, 'min_samples_leaf': 22}\n",
      "Accuracy 0.755\n",
      "RandomForestClassifier {'max_depth': 10, 'min_samples_leaf': 5, 'n_estimators': 300}\n",
      "Accuracy 0.78\n",
      "LogisticRegression {'C': 100}\n",
      "Accuracy 0.772\n",
      "LGBMClassifier {'boosting_type': 'gbdt', 'learning_rate': 0.0065, 'min_data_in_leaf': 30, 'n_estimators': 300, 'num_leaves': 15, 'objective': 'binary', 'seed': 0}\n",
      "Accuracy 0.768\n",
      "XGBClassifier {'nthread': -1, 'seed': 0}\n",
      "Accuracy 0.766\n",
      "CPU times: user 21.4 s, sys: 380 ms, total: 21.8 s\n",
      "Wall time: 3min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "clf_scores = []\n",
    "for clf, param_grid in zip(clfs, param_grids):\n",
    "    clf_scores.append(grid_cv(clf, param_grid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('SVC', 0.767, {'C': 2, 'kernel': 'linear'}), ('KNeighborsClassifier', 0.758, {'n_neighbors': 14}), ('DecisionTreeClassifier', 0.755, {'max_depth': 7, 'min_samples_leaf': 22}), ('RandomForestClassifier', 0.78, {'max_depth': 10, 'min_samples_leaf': 5, 'n_estimators': 300}), ('LogisticRegression', 0.772, {'C': 100}), ('LGBMClassifier', 0.768, {'boosting_type': 'gbdt', 'learning_rate': 0.0065, 'min_data_in_leaf': 30, 'n_estimators': 300, 'num_leaves': 15, 'objective': 'binary', 'seed': 0}), ('XGBClassifier', 0.766, {'nthread': -1, 'seed': 0})]\n"
     ]
    }
   ],
   "source": [
    "print(clf_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [clf[2] for clf in clf_scores]\n",
    "clf1 = SVC(**params[0])\n",
    "clf2 = KNeighborsClassifier(**params[1])\n",
    "clf3 = DecisionTreeClassifier(**params[2])\n",
    "clf4 = RandomForestClassifier(**params[3])\n",
    "clf5 = LogisticRegression(**params[4])\n",
    "clf6 = LGBMClassifier(**params[5])\n",
    "clf7 = XGBClassifier(**params[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [\n",
    "    (clf1.__class__.__name__, clf1),\n",
    "    (clf2.__class__.__name__, clf2),\n",
    "    (clf3.__class__.__name__, clf3),\n",
    "    (clf4.__class__.__name__, clf4),\n",
    "    (clf5.__class__.__name__, clf5),\n",
    "    (clf6.__class__.__name__, clf6),\n",
    "    (clf7.__class__.__name__, clf7)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of ensembled voting classifier:  0.7749\n"
     ]
    }
   ],
   "source": [
    "kfold = KFold(n_splits=5, random_state=2018)\n",
    "ensemble = VotingClassifier(estimators, n_jobs=-1)\n",
    "results = cross_val_score(ensemble, X_train,y_train, cv=kfold)\n",
    "print(\"Accuracy of ensembled voting classifier: \",results.mean().round(4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
