{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "import re\n",
    "import datetime\n",
    "from textblob import TextBlob\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from ipywidgets import interact, IntSlider\n",
    "plt.style.use(\"seaborn\")\n",
    "%matplotlib inline\n",
    "\n",
    "def split_times(start, df):\n",
    "    start = datetime.datetime.strptime(start, \"%Y-%m-%d %H:%M:%S\")\n",
    "    dates_1 = [start + datetime.timedelta(minutes=15*h) for h in range(0,7)]\n",
    "    dates_1 = [date.strftime(\"%Y-%m-%d %H:%M:%S\") for date in dates_1]\n",
    "\n",
    "    dates_2 = [start + datetime.timedelta(minutes=15*h) if h < 7 else start + datetime.timedelta(minutes=15*(h+0.5)) for h in range(1,8)]\n",
    "    dates_2 = [date.strftime(\"%Y-%m-%d %H:%M:%S\") for date in dates_2]\n",
    "\n",
    "    min_15 = pd.DataFrame()\n",
    "    min_30 = pd.DataFrame()\n",
    "    min_45 = pd.DataFrame()\n",
    "    min_break = pd.DataFrame()\n",
    "    min_60 = pd.DataFrame()\n",
    "    min_75 = pd.DataFrame()\n",
    "    min_90 = pd.DataFrame()\n",
    "    time_splits = [min_15, min_30, min_45, min_break, min_60, min_75, min_90]\n",
    "\n",
    "    for i, (d1, d2) in enumerate(zip(dates_1, dates_2)):\n",
    "        time_splits[i] = df[(df[\"tweet_date\"] >= d1) & (df[\"tweet_date\"] < d2)]\n",
    "\n",
    "    return time_splits\n",
    "\n",
    "def remove_emojis(string): # credit: https://stackoverflow.com/questions/33404752/removing-emojis-from-a-string-in-python\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    return(emoji_pattern.sub(r\"\", string))\n",
    "\n",
    "def format_raw_df(raw_df):\n",
    "    raw_df[\"total\"] = raw_df.sum(axis=1)\n",
    "    raw_df.columns = [\"null\", \"entity\", \"15\", \"30\", \"45\", \"break\", \"60\", \"75\", \"90\", \"total\"]\n",
    "    raw_df.drop(columns=[\"null\"], inplace=True)\n",
    "    remove_RT = (~raw_df[\"entity\"].str.contains(\"RT\")) #removes retweet users as entities\n",
    "    remove_http = (~raw_df[\"entity\"].str.contains(\"http\")) #removes https links as entities\n",
    "    raw_df = raw_df[remove_RT & remove_http]\n",
    "    raw_df.fillna(0, inplace=True)\n",
    "    raw_df.sort_values(by=\"total\",ascending=False, inplace=True)\n",
    "    return raw_df\n",
    "\n",
    "def entities_processing(filename, start, chunk_size=200000, language=\"en\"):\n",
    "    \n",
    "    df = pd.read_csv(filename, names=[\"tweet_id\", \"tweet_date\", \"user_location\", \"tweet\"])\n",
    "    df = df[~df[\"tweet_id\"].duplicated()] #removes duplicates\n",
    "    assert df.shape[1] == 4, \"Max columns exceeded\"\n",
    "        \n",
    "    time_splits = split_times(start, df)\n",
    "\n",
    "    nlp = spacy.load('en')\n",
    "\n",
    "    final_df = pd.DataFrame(columns=[\"entity\", \"frequency\"])\n",
    "    for i, time_split in enumerate(time_splits):    \n",
    "\n",
    "        string = str([tweet for tweet in time_split[\"tweet\"]])\n",
    "        string = remove_emojis(string)\n",
    "\n",
    "        print(\"String length: {}.\".format(len(string)))\n",
    "        chunks = [string[i:i + chunk_size] for i in range(0, len(string), chunk_size)]\n",
    "        print(\"{}/7 - Splitting into {} chunks of {} size.\".format(i+1, len(chunks), chunk_size))\n",
    "\n",
    "        entities_agg = pd.DataFrame()\n",
    "        for chunk in chunks:\n",
    "            print('.', end='', flush=True)\n",
    "            doc = nlp(chunk)\n",
    "\n",
    "            dict_pers = {}\n",
    "            for ent in doc.ents:\n",
    "                if ent.label_ == \"PERSON\":# and \"http\" not in ent.text:\n",
    "                    if ent.text in dict_pers.keys():\n",
    "                        dict_pers[ent.text] += 1\n",
    "                    else:\n",
    "                        dict_pers[ent.text] = 1\n",
    "\n",
    "            entities = pd.DataFrame.from_dict(dict_pers, orient=\"index\")\n",
    "            entities.reset_index(inplace=True)\n",
    "            entities.columns = [\"entity\", \"frequency\"]\n",
    "            entities_agg = pd.concat([entities_agg, entities])\n",
    "\n",
    "        final_agg_df = entities_agg.groupby(by=\"entity\", as_index=False).agg(\"sum\").sort_values(by=\"frequency\", ascending=False)\n",
    "        final_df = pd.merge(final_df, final_agg_df, on=\"entity\", how=\"outer\")\n",
    "    \n",
    "    final_df = format_raw_df(final_df)\n",
    "    \n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = {\n",
    "    \"FRAURU\": [\"tweets-FRA-vs-URU.csv\", \"2018-07-06 14:00:00\"],\n",
    "    \"BELBRA\": [\"tweets-BEL-vs-BRA.csv\", \"2018-07-06 18:00:00\"], \n",
    "    \"ENGSWE\": [\"tweets-ENG-vs-SWE.csv\", \"2018-07-07 14:00:00\"],\n",
    "    \"CRORUS\": [\"tweets-CRO-vs-RUS.csv\",\"2018-07-07 18:00:00\"],\n",
    "    \"FRABEL\": [\"tweets-FRA-vs-BEL.csv\", \"2018-07-10 18:00:00\"],\n",
    "    #\"ENGCRO\": [\"tweets-ENG-vs-CRO.csv\", \"2018-07-11 18:00:00\"]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_entities = entities_processing(matches[\"ENGCRO\"][0], matches[\"ENGCRO\"][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functions to manually clean the aggregated data from each match.\n",
    "\n",
    "def format_england_sweden(final_df):\n",
    "    df = final_df[final_df[\"total\"] > 300] .reset_index(drop=True)\n",
    "\n",
    "    df.iloc[1,1:] = df.iloc[1,1:] + df.iloc[3,1:] + df.iloc[26,:] #merging Maguire rows\n",
    "    df.iloc[5,1:] = df.iloc[5,1:] + df.iloc[7,1:] + df.iloc[22,:] #merging Kane rows\n",
    "    df.iloc[2,1:] = df.iloc[2,1:] + df.iloc[25,1:] #merging Pickford rows\n",
    "    df.iloc[24,1:] = df.iloc[24,1:] + df.iloc[27,1:] #merging Pickford rows\n",
    "\n",
    "    df = df.drop([0,4,6,9,10,12,13,15,16,19,21,23,28,29,30,3,26,7,22,25,27]).sort_values(by=\"total\", ascending=False).reset_index(drop=True)\n",
    "    df[\"entity\"] = [\"Maguire\",\"Kane\",\"Pickford\",\"Sterling\",\"Young\",\"Perisic\",\"Alli\",\"Gareth Southgate\",\n",
    "                \"David Beckham\",\"Lingard\",\"Michael Owen\"]\n",
    "    return df\n",
    "\n",
    "def format_croatia_russia(final_df):\n",
    "    df = final_df[final_df[\"total\"] > 300] .reset_index(drop=True)\n",
    "\n",
    "    df = df.drop([0,1,4]).sort_values(by=\"total\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "    df[\"entity\"] = [\"Putin\", \"Kramaric\"]\n",
    "    return df\n",
    "\n",
    "def format_france_belgium(final_df):\n",
    "    df = final_df[final_df[\"total\"] > 300] .reset_index(drop=True)\n",
    "\n",
    "    df.iloc[0,1:] = df.iloc[0,1:] + df.iloc[9,1:] + df.iloc[20,:] #merging Mbappe rows\n",
    "    df.iloc[1,1:] = df.iloc[1,1:] + df.iloc[6,1:] #merging Hazard rows\n",
    "    df.iloc[2,1:] = df.iloc[2,1:] + df.iloc[7,1:] #merging Lloris rows\n",
    "    df.iloc[3,1:] = df.iloc[3,1:] + df.iloc[12,1:] #merging Henry rows\n",
    "\n",
    "    df = df.drop([4,5,8,14,17,6,9,20,7,12]).sort_values(by=\"total\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "    df[\"entity\"] = [\"Mbappe\",\"Hazard\",\"Lloris\",\"Thierry Henry\",\"Dembele\",\"Roberto Martinez\",\"Danny Murphy\",\"Fellaini\",\n",
    "                    \"De Bruyne\",\"Umtiti\",\"Griezmann\"]\n",
    "    return df\n",
    "\n",
    "def format_belgium_brazil(final_df):\n",
    "    df = final_df[final_df[\"total\"] > 300] .reset_index(drop=True)\n",
    "    \n",
    "    df = df.append(df.iloc[3]).reset_index(drop=True) #splitting Marcelo & Willian\n",
    "    df.iloc[3, 1:] = df.iloc[3, 1:]/2\n",
    "    df.iloc[27, 1:] = df.iloc[27, 1:]/2\n",
    "    df = df.append(df.iloc[5]).reset_index(drop=True) #splitting Witsel & Fellaini\n",
    "    df.iloc[5, 1:] = df.iloc[5, 1:]/2\n",
    "    df.iloc[28, 1:] = df.iloc[28, 1:]/2\n",
    "\n",
    "    df.iloc[2,1:] = df.iloc[2,1:] + df.iloc[4,1:] + df.iloc[11,1:] + df.iloc[24,1:]  #merging Bruyne rows\n",
    "    df.iloc[15,1:] = df.iloc[15,1:] + df.iloc[28,1:] #merging Fellaini rows\n",
    "    df.iloc[9,1:] = df.iloc[9,1:] + df.iloc[16,1:] + df.iloc[19,1:] +df.iloc[18,1:] #merging Augusto rows\n",
    "    df.iloc[10,1:] = df.iloc[10,1:] + df.iloc[21,1:] + df.iloc[22,1:] #merging Jesus rows\n",
    "\n",
    "    df = df.drop([6,7,8,12,14,17,18,20,11,24,28,4,16,19,18,21,22,23,25]).sort_values(by=\"total\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "    df[\"entity\"] = [\"Neymar\",\"De Bruyne\",\"Hazard\",\"Renato Augusto\",\"Gabriel Jesus\",\"Fellaini\",\"Marcelo\",\n",
    "                    \"Willian\",\"Witsel\",\"Firmino\",\"Roberto Martinez\"]\n",
    "    return df\n",
    "\n",
    "def format_france_uruguay(final_df):\n",
    "    df = final_df[final_df[\"total\"] > 300] .reset_index(drop=True)\n",
    "    \n",
    "    df.iloc[4,1:] = df.iloc[4,1:] + df.iloc[9,1:] #merging Suarez rows\n",
    "    df.iloc[5,1:] = df.iloc[5,1:] + df.iloc[7,1:] #merging Lloris rows\n",
    "    df.iloc[8,1:] = df.iloc[8,1:] + df.iloc[15,1:] + df.iloc[16,1:] +df.iloc[18,1:] #merging Varane rows\n",
    "    df.iloc[1,1:] = df.iloc[1,1:] + df.iloc[17,1:] #merging Mbappe rows\n",
    "    df.iloc[14,1:] = df.iloc[14,1:] + df.iloc[19,1:] #merging Griezzman rows\n",
    "    df.iloc[11,1:] = df.iloc[11,1:] + df.iloc[21,1:] #merging Muslera rows\n",
    "\n",
    "    df = df.drop([1, 10, 13, 9, 7, 15, 16, 18, 17, 19, 21]).sort_values(by=\"total\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "    df[\"entity\"] = [\"Mbappe\",\"Neymar\",\"Varane\",\"Suarez\",\"Lloris\",\"Karius\",\"Cavani\",\"Muslera\",\n",
    "                    \"Griezzman\",\"De Gea\",\"Pele\"]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv(\"ENG-vs-SWE.csv\")\n",
    "#df.to_csv(\"BEL-vs-BRA.csv\")\n",
    "#df.to_csv(\"FRA-vs-BEL.csv\")\n",
    "#df.to_csv(\"CRO-vs-RUS.csv\")\n",
    "#df.to_csv(\"FRA-vs-URU.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "quarterfinals = [pd.read_csv(filename, index_col=0) for filename in\n",
    "                 [\"FRA-vs-URU.csv\", \"BEL-vs-BRA.csv\", \"ENG-vs-SWE.csv\", \"CRO-vs-RUS.csv\"]]\n",
    "semifinals = [pd.read_csv(filename, index_col=0) for filename in\n",
    "                 [\"FRA-vs-BEL.csv\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d049c5703106483fb537c6f797e0e0cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>interactive</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='minute_split', max=7), Dropdown(description='match', options=('FRA vs URU', 'BEL vs BRA', 'ENG vs SWE', 'CRO vs RUS'), value='FRA vs URU'), Output()), _dom_classes=('widget-interact',))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f998a1e0fe3b4ac5ad42e6b78ff1bc8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>interactive</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='minute_split', max=7), Dropdown(description='match', options=('FRA vs BEL',), value='FRA vs BEL'), Output()), _dom_classes=('widget-interact',))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact(minute_split = IntSlider(min=0,max=7,step=1,value=0), match=[\"FRA vs URU\", \"BEL vs BRA\", \"ENG vs SWE\", \"CRO vs RUS\"])\n",
    "def display_entities(minute_split, match=\"FRA vs URU\"):\n",
    "    dict_key_col = {0:\"total\", 1:\"15\", 2:\"30\", 3:\"45\", 4:\"break\", 5:\"60\", 6:\"75\", 7:\"90\"}\n",
    "    dict_key_title = {0:\"Total Number of Mentions\", 1:\"Mentions at 0-15 mins\", 2:\"Mentions at 15-30 mins\",\n",
    "                      3:\"Mentions at 30-45 mins\", 4:\"Mentions during break\",5:\"Mentions at 45-60 mins\",\n",
    "                      6:\"Mentions at 60-75 mins\", 7:\"Mentions at 75-90 mins\"}\n",
    "    dict_key_df = {\"FRA vs URU\":quarterfinals[0], \"BEL vs BRA\":quarterfinals[1],\n",
    "                  \"ENG vs SWE\": quarterfinals[2], \"CRO vs RUS\": quarterfinals[3]}\n",
    "    \n",
    "    y_pos = np.arange(dict_key_df[match][dict_key_col[minute_split]].shape[0])[::-1]\n",
    "    labels = dict_key_df[match][\"entity\"]\n",
    "    \n",
    "    plt.figure(figsize=(8,6))\n",
    "    plt.barh(y_pos, dict_key_df[match][dict_key_col[minute_split]])\n",
    "    plt.yticks(y_pos, labels)\n",
    "    plt.xlim(0,4000)\n",
    "    plt.title(\"Quarterfinals - \" + dict_key_title[minute_split])\n",
    "    plt.show()\n",
    "    \n",
    "@interact(minute_split = IntSlider(min=0,max=7,step=1,value=0), match=[\"FRA vs BEL\"])\n",
    "def display_entities(minute_split, match=\"FRA vs BEL\"):\n",
    "    dict_key_col = {0:\"total\", 1:\"15\", 2:\"30\", 3:\"45\", 4:\"break\", 5:\"60\", 6:\"75\", 7:\"90\"}\n",
    "    dict_key_title = {0:\"Total Number of Mentions\", 1:\"Mentions at 0-15 mins\", 2:\"Mentions at 15-30 mins\",\n",
    "                      3:\"Mentions at 30-45 mins\", 4:\"Mentions during break\",5:\"Mentions at 45-60 mins\",\n",
    "                      6:\"Mentions at 60-75 mins\", 7:\"Mentions at 75-90 mins\"}\n",
    "    dict_key_df = {\"FRA vs BEL\":semifinals[0]}\n",
    "    \n",
    "    y_pos = np.arange(dict_key_df[match][dict_key_col[minute_split]].shape[0])[::-1]\n",
    "    labels = dict_key_df[match][\"entity\"]\n",
    "    \n",
    "    plt.figure(figsize=(8,6))\n",
    "    plt.barh(y_pos, dict_key_df[match][dict_key_col[minute_split]])\n",
    "    plt.yticks(y_pos, labels)\n",
    "    plt.xlim(0,6500)\n",
    "    plt.title(\"Semifinals - \" + dict_key_title[minute_split])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def sentiment(names ,start_times):\n",
    "    final_data = {}\n",
    "    \n",
    "    for name, start_time in zip(names, start_times):\n",
    "        print('.', end='', flush=True)\n",
    "        stop_time = datetime.datetime.strptime(start_time, \"%Y-%m-%d %H:%M:%S\") + datetime.timedelta(hours=2)\n",
    "        stop_time = stop_time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "        df = pd.read_csv(name, names=[\"tweet_id\", \"tweet_date\", \"user_location\", \"tweet\"])\n",
    "        df = df[(df[\"tweet_date\"] > start_time) & (df[\"tweet_date\"] < stop_time)]\n",
    "        df[name] = [TextBlob(remove_emojis(tweet)).sentiment.polarity for tweet in df[\"tweet\"]]\n",
    "\n",
    "        groupped_df = df[[\"tweet_date\", name]].groupby(by=\"tweet_date\", as_index=False).agg(\"mean\") #each second during the 2 hours after the game\n",
    "        final_data[name] = groupped_df[name].tolist()\n",
    "    return final_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....."
     ]
    }
   ],
   "source": [
    "names_matches = [match[0] for match in matches.values()]\n",
    "start_matches = [match[1] for match in matches.values()]\n",
    "\n",
    "sentiment_data = sentiment(names_matches, start_matches)\n",
    "names_sentiments = list(sentiment_data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01608d573b81411d80466e576d2cc098",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>interactive</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "interactive(children=(Dropdown(description='match', options=('tweets-FRA-vs-URU.csv', 'tweets-BEL-vs-BRA.csv', 'tweets-ENG-vs-SWE.csv', 'tweets-CRO-vs-RUS.csv'), value='tweets-FRA-vs-URU.csv'), Output()), _dom_classes=('widget-interact',))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a71f3fe4101343729afb5020319a2d8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>interactive</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "interactive(children=(Text(value='tweets-FRA-vs-BEL.csv', description='match'), Output()), _dom_classes=('widget-interact',))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact(match=names_sentiments[:-1])\n",
    "def display_entities(match=names_sentiments[0]):\n",
    "    plt.figure(figsize=(12,6))\n",
    "    plt.plot(sentiment_data[match])\n",
    "    plt.ylim(-1,1)\n",
    "    plt.show()\n",
    "    \n",
    "@interact(match=names_sentiments[-1])\n",
    "def display_entities(match=names_sentiments[0]):\n",
    "    plt.figure(figsize=(12,6))\n",
    "    plt.plot(sentiment_data[match])\n",
    "    plt.ylim(-1,1)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
